{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOL4yTvkX7yQlNrkyBQAPwj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rupalitaneja/Advanced-House-Price-Prediction-/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvoAKGdKocYa"
      },
      "source": [
        "# CHURN MODELLING PREDICTION USING ANN MODEL\r\n",
        "SUBMITTED BY: Rupali18csu182"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtX9JPoNoiNs"
      },
      "source": [
        "Problem Statement: Use ANN model to predict if the customer with the following informations will leave the bank\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN4eJahVadTN"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ZEw2Rknca0B0",
        "outputId": "ff9eadc6-5c08-4423-e890-e8baa3becba4"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4cd6d0c0-4b33-4bad-872f-e024a6326ad1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4cd6d0c0-4b33-4bad-872f-e024a6326ad1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Churn_Modelling.csv to Churn_Modelling.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew5Kp0p1a3y9"
      },
      "source": [
        "df=pd.read_csv(\"Churn_Modelling.csv\")"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "l1CSSJx7bItH",
        "outputId": "4097f709-3bc0-4b38-ba72-24bce5dbb15c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTGGqw3ib5MB",
        "outputId": "c002e4a0-b25f-4155-f875-a50d389e1ee1"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "8TTBRCU8cAXg",
        "outputId": "076b32ab-db94-4496-9f57-eafc9c954b89"
      },
      "source": [
        "df.describe().transpose()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RowNumber</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>5.000500e+03</td>\n",
              "      <td>2886.895680</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2500.75</td>\n",
              "      <td>5.000500e+03</td>\n",
              "      <td>7.500250e+03</td>\n",
              "      <td>10000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CustomerId</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.569094e+07</td>\n",
              "      <td>71936.186123</td>\n",
              "      <td>15565701.00</td>\n",
              "      <td>15628528.25</td>\n",
              "      <td>1.569074e+07</td>\n",
              "      <td>1.575323e+07</td>\n",
              "      <td>15815690.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CreditScore</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>6.505288e+02</td>\n",
              "      <td>96.653299</td>\n",
              "      <td>350.00</td>\n",
              "      <td>584.00</td>\n",
              "      <td>6.520000e+02</td>\n",
              "      <td>7.180000e+02</td>\n",
              "      <td>850.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>3.892180e+01</td>\n",
              "      <td>10.487806</td>\n",
              "      <td>18.00</td>\n",
              "      <td>32.00</td>\n",
              "      <td>3.700000e+01</td>\n",
              "      <td>4.400000e+01</td>\n",
              "      <td>92.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tenure</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>5.012800e+00</td>\n",
              "      <td>2.892174</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balance</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>7.648589e+04</td>\n",
              "      <td>62397.405202</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9.719854e+04</td>\n",
              "      <td>1.276442e+05</td>\n",
              "      <td>250898.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumOfProducts</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.530200e+00</td>\n",
              "      <td>0.581654</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HasCrCard</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>7.055000e-01</td>\n",
              "      <td>0.455840</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IsActiveMember</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>5.151000e-01</td>\n",
              "      <td>0.499797</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.000902e+05</td>\n",
              "      <td>57510.492818</td>\n",
              "      <td>11.58</td>\n",
              "      <td>51002.11</td>\n",
              "      <td>1.001939e+05</td>\n",
              "      <td>1.493882e+05</td>\n",
              "      <td>199992.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exited</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>2.037000e-01</td>\n",
              "      <td>0.402769</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   count          mean  ...           75%          max\n",
              "RowNumber        10000.0  5.000500e+03  ...  7.500250e+03     10000.00\n",
              "CustomerId       10000.0  1.569094e+07  ...  1.575323e+07  15815690.00\n",
              "CreditScore      10000.0  6.505288e+02  ...  7.180000e+02       850.00\n",
              "Age              10000.0  3.892180e+01  ...  4.400000e+01        92.00\n",
              "Tenure           10000.0  5.012800e+00  ...  7.000000e+00        10.00\n",
              "Balance          10000.0  7.648589e+04  ...  1.276442e+05    250898.09\n",
              "NumOfProducts    10000.0  1.530200e+00  ...  2.000000e+00         4.00\n",
              "HasCrCard        10000.0  7.055000e-01  ...  1.000000e+00         1.00\n",
              "IsActiveMember   10000.0  5.151000e-01  ...  1.000000e+00         1.00\n",
              "EstimatedSalary  10000.0  1.000902e+05  ...  1.493882e+05    199992.48\n",
              "Exited           10000.0  2.037000e-01  ...  0.000000e+00         1.00\n",
              "\n",
              "[11 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxiOSi1ncGZ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36DhD_Z-dFJP"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esLXeZqBdHp7"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "XHVuKK7odJ8Y",
        "outputId": "254b241e-b6df-4a8b-e93f-665eb27a6432"
      },
      "source": [
        "sns.countplot(x='Exited',data=df)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb318240f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "FjY1iSdKdNBt",
        "outputId": "786c0756-33a5-4294-9b7c-1401f7b6aeed"
      },
      "source": [
        "sns.heatmap(df.corr())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb317a4438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IORryLkJdQDS",
        "outputId": "2aff3144-d348-49cd-eafc-0bd3c529a2e1"
      },
      "source": [
        "df.corr()['Exited'].sort_values()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IsActiveMember    -0.156128\n",
              "NumOfProducts     -0.047820\n",
              "CreditScore       -0.027094\n",
              "RowNumber         -0.016571\n",
              "Tenure            -0.014001\n",
              "HasCrCard         -0.007138\n",
              "CustomerId        -0.006248\n",
              "EstimatedSalary    0.012097\n",
              "Balance            0.118533\n",
              "Age                0.285323\n",
              "Exited             1.000000\n",
              "Name: Exited, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "jfgZTukcdVuj",
        "outputId": "93b4d1a9-a73d-40fd-8174-ccd9e1f50df1"
      },
      "source": [
        "df.corr()['Exited'][:-1].sort_values().plot(kind='bar')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb289b3d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PVuS7kndrLO"
      },
      "source": [
        "**Splitting the Dataset into train and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzmxkRjtrXqf"
      },
      "source": [
        "df= df.drop(['CustomerId', 'Surname', 'RowNumber'], axis = 1)    ##dropping irrelevant columns\r\n",
        "\r\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hzmPPJjr7pA"
      },
      "source": [
        "X = df.iloc[:,0:10]\r\n",
        "y = df.iloc[:,10]"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOBwG_Mhrok4",
        "outputId": "07764acc-6eb8-4628-917f-fd325c1f04e1"
      },
      "source": [
        "print(X.shape)\r\n",
        "print(y.shape)\r\n",
        "print(X.columns)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "(10000,)\n",
            "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
            "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "YSsM8Yyzipv9",
        "outputId": "cacb5dd8-d0e3-406d-b717-d8e6431a67d9"
      },
      "source": [
        "X = pd.get_dummies(X)\r\n",
        "\r\n",
        "X.head()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Geography_France</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore  Age  Tenure  ...  Geography_Spain  Gender_Female  Gender_Male\n",
              "0          619   42       2  ...                0              1            0\n",
              "1          608   41       1  ...                1              1            0\n",
              "2          502   42       8  ...                0              1            0\n",
              "3          699   39       1  ...                0              1            0\n",
              "4          850   43       2  ...                1              1            0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gmYC0ZJi6SE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhmjLFIGi4pl"
      },
      "source": [
        "**Train and test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK0UhBXfd51J"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amlvI29jeFff"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=101) # trying for splitting ratio ar 20:80"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsYHFXYAeKl-"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scaler = MinMaxScaler()\r\n",
        "scaler.fit(X_train)\r\n",
        "X_train = scaler.transform(X_train)\r\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eZQxgG-fj8S"
      },
      "source": [
        "**Creating the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRn87CMced9X"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdWqpGh_fpBh",
        "outputId": "68dbfd69-c307-47e3-8854-b5a003d97050"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM01yGnvfqpl"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(units=13,activation='relu'))\r\n",
        "model.add(Dense(units=7,activation='relu'))\r\n",
        "model.add(Dense(units=1,activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ViCWrFvgPSl",
        "outputId": "352fd7ef-eb39-49cc-8459-3f731353b43d"
      },
      "source": [
        "#METHOD 1: considering number of epochs as 600\r\n",
        "model.fit(x=X_train, \r\n",
        "          y=y_train, \r\n",
        "          epochs=600,\r\n",
        "          validation_data=(X_test, y_test), verbose=1\r\n",
        "          )"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6902 - val_loss: 0.5057 - val_accuracy: 0.7885\n",
            "Epoch 2/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8035 - val_loss: 0.4805 - val_accuracy: 0.7875\n",
            "Epoch 3/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8106 - val_loss: 0.4683 - val_accuracy: 0.7910\n",
            "Epoch 4/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8044 - val_loss: 0.4581 - val_accuracy: 0.7985\n",
            "Epoch 5/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8113 - val_loss: 0.4494 - val_accuracy: 0.8030\n",
            "Epoch 6/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8104 - val_loss: 0.4405 - val_accuracy: 0.8030\n",
            "Epoch 7/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8092 - val_loss: 0.4333 - val_accuracy: 0.8050\n",
            "Epoch 8/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8165 - val_loss: 0.4281 - val_accuracy: 0.8055\n",
            "Epoch 9/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8215 - val_loss: 0.4238 - val_accuracy: 0.8095\n",
            "Epoch 10/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8252 - val_loss: 0.4229 - val_accuracy: 0.8070\n",
            "Epoch 11/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8192 - val_loss: 0.4173 - val_accuracy: 0.8155\n",
            "Epoch 12/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8295 - val_loss: 0.4145 - val_accuracy: 0.8160\n",
            "Epoch 13/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8216 - val_loss: 0.4127 - val_accuracy: 0.8175\n",
            "Epoch 14/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8212 - val_loss: 0.4103 - val_accuracy: 0.8185\n",
            "Epoch 15/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8306 - val_loss: 0.4064 - val_accuracy: 0.8225\n",
            "Epoch 16/600\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4077 - accuracy: 0.8296 - val_loss: 0.4048 - val_accuracy: 0.8210\n",
            "Epoch 17/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8271 - val_loss: 0.4023 - val_accuracy: 0.8230\n",
            "Epoch 18/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8249 - val_loss: 0.3954 - val_accuracy: 0.8300\n",
            "Epoch 19/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8374 - val_loss: 0.3891 - val_accuracy: 0.8370\n",
            "Epoch 20/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8333 - val_loss: 0.3813 - val_accuracy: 0.8410\n",
            "Epoch 21/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8411 - val_loss: 0.3733 - val_accuracy: 0.8425\n",
            "Epoch 22/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8378 - val_loss: 0.3648 - val_accuracy: 0.8450\n",
            "Epoch 23/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8458 - val_loss: 0.3594 - val_accuracy: 0.8460\n",
            "Epoch 24/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8609 - val_loss: 0.3543 - val_accuracy: 0.8470\n",
            "Epoch 25/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8575 - val_loss: 0.3507 - val_accuracy: 0.8495\n",
            "Epoch 26/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8532 - val_loss: 0.3466 - val_accuracy: 0.8510\n",
            "Epoch 27/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8586 - val_loss: 0.3451 - val_accuracy: 0.8515\n",
            "Epoch 28/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8570 - val_loss: 0.3434 - val_accuracy: 0.8545\n",
            "Epoch 29/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8570 - val_loss: 0.3413 - val_accuracy: 0.8535\n",
            "Epoch 30/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8585 - val_loss: 0.3420 - val_accuracy: 0.8555\n",
            "Epoch 31/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8577 - val_loss: 0.3387 - val_accuracy: 0.8555\n",
            "Epoch 32/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8603 - val_loss: 0.3382 - val_accuracy: 0.8565\n",
            "Epoch 33/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8599 - val_loss: 0.3393 - val_accuracy: 0.8570\n",
            "Epoch 34/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8545 - val_loss: 0.3380 - val_accuracy: 0.8540\n",
            "Epoch 35/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8544 - val_loss: 0.3396 - val_accuracy: 0.8560\n",
            "Epoch 36/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8525 - val_loss: 0.3357 - val_accuracy: 0.8550\n",
            "Epoch 37/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8546 - val_loss: 0.3359 - val_accuracy: 0.8540\n",
            "Epoch 38/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8587 - val_loss: 0.3349 - val_accuracy: 0.8560\n",
            "Epoch 39/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8555 - val_loss: 0.3351 - val_accuracy: 0.8525\n",
            "Epoch 40/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8565 - val_loss: 0.3340 - val_accuracy: 0.8565\n",
            "Epoch 41/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8579 - val_loss: 0.3385 - val_accuracy: 0.8540\n",
            "Epoch 42/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8581 - val_loss: 0.3344 - val_accuracy: 0.8560\n",
            "Epoch 43/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8552 - val_loss: 0.3348 - val_accuracy: 0.8555\n",
            "Epoch 44/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8578 - val_loss: 0.3344 - val_accuracy: 0.8560\n",
            "Epoch 45/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8593 - val_loss: 0.3342 - val_accuracy: 0.8595\n",
            "Epoch 46/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8621 - val_loss: 0.3362 - val_accuracy: 0.8550\n",
            "Epoch 47/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8608 - val_loss: 0.3337 - val_accuracy: 0.8545\n",
            "Epoch 48/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8527 - val_loss: 0.3320 - val_accuracy: 0.8570\n",
            "Epoch 49/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8550 - val_loss: 0.3314 - val_accuracy: 0.8585\n",
            "Epoch 50/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8611 - val_loss: 0.3343 - val_accuracy: 0.8535\n",
            "Epoch 51/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8649 - val_loss: 0.3321 - val_accuracy: 0.8590\n",
            "Epoch 52/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8607 - val_loss: 0.3333 - val_accuracy: 0.8565\n",
            "Epoch 53/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8609 - val_loss: 0.3330 - val_accuracy: 0.8560\n",
            "Epoch 54/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8510 - val_loss: 0.3318 - val_accuracy: 0.8560\n",
            "Epoch 55/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8539 - val_loss: 0.3327 - val_accuracy: 0.8595\n",
            "Epoch 56/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3514 - accuracy: 0.8532 - val_loss: 0.3334 - val_accuracy: 0.8565\n",
            "Epoch 57/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8528 - val_loss: 0.3315 - val_accuracy: 0.8580\n",
            "Epoch 58/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8534 - val_loss: 0.3317 - val_accuracy: 0.8565\n",
            "Epoch 59/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8568 - val_loss: 0.3322 - val_accuracy: 0.8610\n",
            "Epoch 60/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8605 - val_loss: 0.3311 - val_accuracy: 0.8580\n",
            "Epoch 61/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8520 - val_loss: 0.3314 - val_accuracy: 0.8590\n",
            "Epoch 62/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8606 - val_loss: 0.3308 - val_accuracy: 0.8595\n",
            "Epoch 63/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8549 - val_loss: 0.3310 - val_accuracy: 0.8585\n",
            "Epoch 64/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8603 - val_loss: 0.3302 - val_accuracy: 0.8575\n",
            "Epoch 65/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8586 - val_loss: 0.3362 - val_accuracy: 0.8595\n",
            "Epoch 66/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8660 - val_loss: 0.3336 - val_accuracy: 0.8590\n",
            "Epoch 67/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8645 - val_loss: 0.3353 - val_accuracy: 0.8575\n",
            "Epoch 68/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8571 - val_loss: 0.3328 - val_accuracy: 0.8585\n",
            "Epoch 69/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8611 - val_loss: 0.3308 - val_accuracy: 0.8580\n",
            "Epoch 70/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8596 - val_loss: 0.3322 - val_accuracy: 0.8600\n",
            "Epoch 71/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8683 - val_loss: 0.3320 - val_accuracy: 0.8595\n",
            "Epoch 72/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8581 - val_loss: 0.3314 - val_accuracy: 0.8585\n",
            "Epoch 73/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8505 - val_loss: 0.3299 - val_accuracy: 0.8595\n",
            "Epoch 74/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8617 - val_loss: 0.3321 - val_accuracy: 0.8590\n",
            "Epoch 75/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8530 - val_loss: 0.3334 - val_accuracy: 0.8610\n",
            "Epoch 76/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8584 - val_loss: 0.3331 - val_accuracy: 0.8610\n",
            "Epoch 77/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8550 - val_loss: 0.3297 - val_accuracy: 0.8610\n",
            "Epoch 78/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8653 - val_loss: 0.3297 - val_accuracy: 0.8620\n",
            "Epoch 79/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8657 - val_loss: 0.3291 - val_accuracy: 0.8620\n",
            "Epoch 80/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8596 - val_loss: 0.3301 - val_accuracy: 0.8595\n",
            "Epoch 81/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8543 - val_loss: 0.3340 - val_accuracy: 0.8590\n",
            "Epoch 82/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8694 - val_loss: 0.3332 - val_accuracy: 0.8600\n",
            "Epoch 83/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8580 - val_loss: 0.3313 - val_accuracy: 0.8605\n",
            "Epoch 84/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8641 - val_loss: 0.3305 - val_accuracy: 0.8620\n",
            "Epoch 85/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8661 - val_loss: 0.3310 - val_accuracy: 0.8625\n",
            "Epoch 86/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8610 - val_loss: 0.3286 - val_accuracy: 0.8625\n",
            "Epoch 87/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8644 - val_loss: 0.3291 - val_accuracy: 0.8630\n",
            "Epoch 88/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8609 - val_loss: 0.3295 - val_accuracy: 0.8645\n",
            "Epoch 89/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8620 - val_loss: 0.3292 - val_accuracy: 0.8620\n",
            "Epoch 90/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8566 - val_loss: 0.3342 - val_accuracy: 0.8555\n",
            "Epoch 91/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8636 - val_loss: 0.3292 - val_accuracy: 0.8620\n",
            "Epoch 92/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8622 - val_loss: 0.3293 - val_accuracy: 0.8595\n",
            "Epoch 93/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8550 - val_loss: 0.3315 - val_accuracy: 0.8595\n",
            "Epoch 94/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8633 - val_loss: 0.3307 - val_accuracy: 0.8605\n",
            "Epoch 95/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8596 - val_loss: 0.3334 - val_accuracy: 0.8580\n",
            "Epoch 96/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8512 - val_loss: 0.3304 - val_accuracy: 0.8585\n",
            "Epoch 97/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8558 - val_loss: 0.3304 - val_accuracy: 0.8605\n",
            "Epoch 98/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8603 - val_loss: 0.3314 - val_accuracy: 0.8625\n",
            "Epoch 99/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8562 - val_loss: 0.3310 - val_accuracy: 0.8595\n",
            "Epoch 100/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8671 - val_loss: 0.3288 - val_accuracy: 0.8620\n",
            "Epoch 101/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8575 - val_loss: 0.3308 - val_accuracy: 0.8615\n",
            "Epoch 102/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8569 - val_loss: 0.3298 - val_accuracy: 0.8595\n",
            "Epoch 103/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8664 - val_loss: 0.3311 - val_accuracy: 0.8590\n",
            "Epoch 104/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8595 - val_loss: 0.3297 - val_accuracy: 0.8610\n",
            "Epoch 105/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8631 - val_loss: 0.3288 - val_accuracy: 0.8595\n",
            "Epoch 106/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8605 - val_loss: 0.3295 - val_accuracy: 0.8605\n",
            "Epoch 107/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8562 - val_loss: 0.3328 - val_accuracy: 0.8595\n",
            "Epoch 108/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8615 - val_loss: 0.3294 - val_accuracy: 0.8630\n",
            "Epoch 109/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8674 - val_loss: 0.3288 - val_accuracy: 0.8615\n",
            "Epoch 110/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8630 - val_loss: 0.3286 - val_accuracy: 0.8585\n",
            "Epoch 111/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8591 - val_loss: 0.3297 - val_accuracy: 0.8625\n",
            "Epoch 112/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8617 - val_loss: 0.3295 - val_accuracy: 0.8645\n",
            "Epoch 113/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8555 - val_loss: 0.3297 - val_accuracy: 0.8605\n",
            "Epoch 114/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8572 - val_loss: 0.3288 - val_accuracy: 0.8640\n",
            "Epoch 115/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8552 - val_loss: 0.3328 - val_accuracy: 0.8615\n",
            "Epoch 116/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8644 - val_loss: 0.3295 - val_accuracy: 0.8610\n",
            "Epoch 117/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8586 - val_loss: 0.3314 - val_accuracy: 0.8600\n",
            "Epoch 118/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8636 - val_loss: 0.3281 - val_accuracy: 0.8615\n",
            "Epoch 119/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8640 - val_loss: 0.3273 - val_accuracy: 0.8610\n",
            "Epoch 120/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8612 - val_loss: 0.3312 - val_accuracy: 0.8630\n",
            "Epoch 121/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3310 - accuracy: 0.8648 - val_loss: 0.3298 - val_accuracy: 0.8605\n",
            "Epoch 122/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8644 - val_loss: 0.3295 - val_accuracy: 0.8620\n",
            "Epoch 123/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8616 - val_loss: 0.3307 - val_accuracy: 0.8615\n",
            "Epoch 124/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8613 - val_loss: 0.3302 - val_accuracy: 0.8620\n",
            "Epoch 125/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8632 - val_loss: 0.3286 - val_accuracy: 0.8620\n",
            "Epoch 126/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8709 - val_loss: 0.3380 - val_accuracy: 0.8600\n",
            "Epoch 127/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8639 - val_loss: 0.3276 - val_accuracy: 0.8640\n",
            "Epoch 128/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8636 - val_loss: 0.3321 - val_accuracy: 0.8605\n",
            "Epoch 129/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8641 - val_loss: 0.3305 - val_accuracy: 0.8605\n",
            "Epoch 130/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8539 - val_loss: 0.3280 - val_accuracy: 0.8645\n",
            "Epoch 131/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8610 - val_loss: 0.3287 - val_accuracy: 0.8645\n",
            "Epoch 132/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8584 - val_loss: 0.3274 - val_accuracy: 0.8605\n",
            "Epoch 133/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8624 - val_loss: 0.3281 - val_accuracy: 0.8605\n",
            "Epoch 134/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8654 - val_loss: 0.3291 - val_accuracy: 0.8630\n",
            "Epoch 135/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8658 - val_loss: 0.3306 - val_accuracy: 0.8635\n",
            "Epoch 136/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8696 - val_loss: 0.3282 - val_accuracy: 0.8620\n",
            "Epoch 137/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8623 - val_loss: 0.3279 - val_accuracy: 0.8615\n",
            "Epoch 138/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8611 - val_loss: 0.3290 - val_accuracy: 0.8640\n",
            "Epoch 139/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8585 - val_loss: 0.3304 - val_accuracy: 0.8620\n",
            "Epoch 140/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8710 - val_loss: 0.3277 - val_accuracy: 0.8650\n",
            "Epoch 141/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8596 - val_loss: 0.3281 - val_accuracy: 0.8635\n",
            "Epoch 142/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8658 - val_loss: 0.3281 - val_accuracy: 0.8630\n",
            "Epoch 143/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8681 - val_loss: 0.3303 - val_accuracy: 0.8630\n",
            "Epoch 144/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8613 - val_loss: 0.3281 - val_accuracy: 0.8630\n",
            "Epoch 145/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8676 - val_loss: 0.3261 - val_accuracy: 0.8625\n",
            "Epoch 146/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8614 - val_loss: 0.3261 - val_accuracy: 0.8640\n",
            "Epoch 147/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8552 - val_loss: 0.3256 - val_accuracy: 0.8660\n",
            "Epoch 148/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8606 - val_loss: 0.3274 - val_accuracy: 0.8675\n",
            "Epoch 149/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8657 - val_loss: 0.3269 - val_accuracy: 0.8645\n",
            "Epoch 150/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8672 - val_loss: 0.3269 - val_accuracy: 0.8645\n",
            "Epoch 151/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8657 - val_loss: 0.3276 - val_accuracy: 0.8660\n",
            "Epoch 152/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8672 - val_loss: 0.3269 - val_accuracy: 0.8630\n",
            "Epoch 153/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8654 - val_loss: 0.3269 - val_accuracy: 0.8635\n",
            "Epoch 154/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8689 - val_loss: 0.3256 - val_accuracy: 0.8660\n",
            "Epoch 155/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8661 - val_loss: 0.3270 - val_accuracy: 0.8665\n",
            "Epoch 156/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8633 - val_loss: 0.3292 - val_accuracy: 0.8620\n",
            "Epoch 157/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8569 - val_loss: 0.3271 - val_accuracy: 0.8645\n",
            "Epoch 158/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8662 - val_loss: 0.3279 - val_accuracy: 0.8615\n",
            "Epoch 159/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8632 - val_loss: 0.3256 - val_accuracy: 0.8680\n",
            "Epoch 160/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8643 - val_loss: 0.3285 - val_accuracy: 0.8635\n",
            "Epoch 161/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8635 - val_loss: 0.3301 - val_accuracy: 0.8620\n",
            "Epoch 162/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8689 - val_loss: 0.3293 - val_accuracy: 0.8645\n",
            "Epoch 163/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8565 - val_loss: 0.3271 - val_accuracy: 0.8625\n",
            "Epoch 164/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8692 - val_loss: 0.3280 - val_accuracy: 0.8650\n",
            "Epoch 165/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8655 - val_loss: 0.3259 - val_accuracy: 0.8655\n",
            "Epoch 166/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8645 - val_loss: 0.3275 - val_accuracy: 0.8635\n",
            "Epoch 167/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8581 - val_loss: 0.3250 - val_accuracy: 0.8675\n",
            "Epoch 168/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8677 - val_loss: 0.3280 - val_accuracy: 0.8600\n",
            "Epoch 169/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8672 - val_loss: 0.3283 - val_accuracy: 0.8630\n",
            "Epoch 170/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8618 - val_loss: 0.3292 - val_accuracy: 0.8650\n",
            "Epoch 171/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8617 - val_loss: 0.3292 - val_accuracy: 0.8630\n",
            "Epoch 172/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8655 - val_loss: 0.3284 - val_accuracy: 0.8640\n",
            "Epoch 173/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8628 - val_loss: 0.3258 - val_accuracy: 0.8660\n",
            "Epoch 174/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8665 - val_loss: 0.3294 - val_accuracy: 0.8655\n",
            "Epoch 175/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8620 - val_loss: 0.3301 - val_accuracy: 0.8630\n",
            "Epoch 176/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8644 - val_loss: 0.3270 - val_accuracy: 0.8655\n",
            "Epoch 177/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8609 - val_loss: 0.3256 - val_accuracy: 0.8655\n",
            "Epoch 178/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8630 - val_loss: 0.3291 - val_accuracy: 0.8605\n",
            "Epoch 179/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8613 - val_loss: 0.3274 - val_accuracy: 0.8650\n",
            "Epoch 180/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8691 - val_loss: 0.3285 - val_accuracy: 0.8630\n",
            "Epoch 181/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8678 - val_loss: 0.3287 - val_accuracy: 0.8640\n",
            "Epoch 182/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8639 - val_loss: 0.3264 - val_accuracy: 0.8685\n",
            "Epoch 183/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8594 - val_loss: 0.3251 - val_accuracy: 0.8655\n",
            "Epoch 184/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8640 - val_loss: 0.3268 - val_accuracy: 0.8650\n",
            "Epoch 185/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8688 - val_loss: 0.3280 - val_accuracy: 0.8615\n",
            "Epoch 186/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.8645 - val_loss: 0.3281 - val_accuracy: 0.8655\n",
            "Epoch 187/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8685 - val_loss: 0.3280 - val_accuracy: 0.8690\n",
            "Epoch 188/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8679 - val_loss: 0.3281 - val_accuracy: 0.8680\n",
            "Epoch 189/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8620 - val_loss: 0.3253 - val_accuracy: 0.8645\n",
            "Epoch 190/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8623 - val_loss: 0.3274 - val_accuracy: 0.8620\n",
            "Epoch 191/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8654 - val_loss: 0.3269 - val_accuracy: 0.8625\n",
            "Epoch 192/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8717 - val_loss: 0.3274 - val_accuracy: 0.8635\n",
            "Epoch 193/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8680 - val_loss: 0.3275 - val_accuracy: 0.8660\n",
            "Epoch 194/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8703 - val_loss: 0.3267 - val_accuracy: 0.8635\n",
            "Epoch 195/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8636 - val_loss: 0.3249 - val_accuracy: 0.8635\n",
            "Epoch 196/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8644 - val_loss: 0.3271 - val_accuracy: 0.8675\n",
            "Epoch 197/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8675 - val_loss: 0.3266 - val_accuracy: 0.8655\n",
            "Epoch 198/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8617 - val_loss: 0.3270 - val_accuracy: 0.8635\n",
            "Epoch 199/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8621 - val_loss: 0.3257 - val_accuracy: 0.8635\n",
            "Epoch 200/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8697 - val_loss: 0.3284 - val_accuracy: 0.8650\n",
            "Epoch 201/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8613 - val_loss: 0.3272 - val_accuracy: 0.8610\n",
            "Epoch 202/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8622 - val_loss: 0.3297 - val_accuracy: 0.8620\n",
            "Epoch 203/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8665 - val_loss: 0.3273 - val_accuracy: 0.8665\n",
            "Epoch 204/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8635 - val_loss: 0.3270 - val_accuracy: 0.8635\n",
            "Epoch 205/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8737 - val_loss: 0.3272 - val_accuracy: 0.8640\n",
            "Epoch 206/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8717 - val_loss: 0.3253 - val_accuracy: 0.8675\n",
            "Epoch 207/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8751 - val_loss: 0.3252 - val_accuracy: 0.8655\n",
            "Epoch 208/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8695 - val_loss: 0.3276 - val_accuracy: 0.8650\n",
            "Epoch 209/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8658 - val_loss: 0.3279 - val_accuracy: 0.8640\n",
            "Epoch 210/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8614 - val_loss: 0.3278 - val_accuracy: 0.8640\n",
            "Epoch 211/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8695 - val_loss: 0.3286 - val_accuracy: 0.8665\n",
            "Epoch 212/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8641 - val_loss: 0.3265 - val_accuracy: 0.8645\n",
            "Epoch 213/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8717 - val_loss: 0.3288 - val_accuracy: 0.8655\n",
            "Epoch 214/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8690 - val_loss: 0.3264 - val_accuracy: 0.8640\n",
            "Epoch 215/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8661 - val_loss: 0.3270 - val_accuracy: 0.8645\n",
            "Epoch 216/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8701 - val_loss: 0.3262 - val_accuracy: 0.8645\n",
            "Epoch 217/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8624 - val_loss: 0.3273 - val_accuracy: 0.8640\n",
            "Epoch 218/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8664 - val_loss: 0.3270 - val_accuracy: 0.8640\n",
            "Epoch 219/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8748 - val_loss: 0.3311 - val_accuracy: 0.8625\n",
            "Epoch 220/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8677 - val_loss: 0.3275 - val_accuracy: 0.8650\n",
            "Epoch 221/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8671 - val_loss: 0.3274 - val_accuracy: 0.8630\n",
            "Epoch 222/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8560 - val_loss: 0.3269 - val_accuracy: 0.8670\n",
            "Epoch 223/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8699 - val_loss: 0.3270 - val_accuracy: 0.8625\n",
            "Epoch 224/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8655 - val_loss: 0.3265 - val_accuracy: 0.8680\n",
            "Epoch 225/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8678 - val_loss: 0.3260 - val_accuracy: 0.8665\n",
            "Epoch 226/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8616 - val_loss: 0.3276 - val_accuracy: 0.8660\n",
            "Epoch 227/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8673 - val_loss: 0.3282 - val_accuracy: 0.8655\n",
            "Epoch 228/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8662 - val_loss: 0.3264 - val_accuracy: 0.8650\n",
            "Epoch 229/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8673 - val_loss: 0.3283 - val_accuracy: 0.8640\n",
            "Epoch 230/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8567 - val_loss: 0.3280 - val_accuracy: 0.8670\n",
            "Epoch 231/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8676 - val_loss: 0.3271 - val_accuracy: 0.8685\n",
            "Epoch 232/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8709 - val_loss: 0.3296 - val_accuracy: 0.8645\n",
            "Epoch 233/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8685 - val_loss: 0.3265 - val_accuracy: 0.8660\n",
            "Epoch 234/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8653 - val_loss: 0.3269 - val_accuracy: 0.8680\n",
            "Epoch 235/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8708 - val_loss: 0.3275 - val_accuracy: 0.8655\n",
            "Epoch 236/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8660 - val_loss: 0.3257 - val_accuracy: 0.8675\n",
            "Epoch 237/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8682 - val_loss: 0.3276 - val_accuracy: 0.8680\n",
            "Epoch 238/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8676 - val_loss: 0.3279 - val_accuracy: 0.8665\n",
            "Epoch 239/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8632 - val_loss: 0.3279 - val_accuracy: 0.8650\n",
            "Epoch 240/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8688 - val_loss: 0.3276 - val_accuracy: 0.8650\n",
            "Epoch 241/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8674 - val_loss: 0.3266 - val_accuracy: 0.8665\n",
            "Epoch 242/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8624 - val_loss: 0.3262 - val_accuracy: 0.8670\n",
            "Epoch 243/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8655 - val_loss: 0.3328 - val_accuracy: 0.8640\n",
            "Epoch 244/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8669 - val_loss: 0.3257 - val_accuracy: 0.8650\n",
            "Epoch 245/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8662 - val_loss: 0.3262 - val_accuracy: 0.8630\n",
            "Epoch 246/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8619 - val_loss: 0.3260 - val_accuracy: 0.8690\n",
            "Epoch 247/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8627 - val_loss: 0.3262 - val_accuracy: 0.8680\n",
            "Epoch 248/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8695 - val_loss: 0.3263 - val_accuracy: 0.8675\n",
            "Epoch 249/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8646 - val_loss: 0.3297 - val_accuracy: 0.8635\n",
            "Epoch 250/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8632 - val_loss: 0.3268 - val_accuracy: 0.8680\n",
            "Epoch 251/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8596 - val_loss: 0.3258 - val_accuracy: 0.8670\n",
            "Epoch 252/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3204 - accuracy: 0.8652 - val_loss: 0.3254 - val_accuracy: 0.8690\n",
            "Epoch 253/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8679 - val_loss: 0.3287 - val_accuracy: 0.8635\n",
            "Epoch 254/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8668 - val_loss: 0.3257 - val_accuracy: 0.8665\n",
            "Epoch 255/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8582 - val_loss: 0.3320 - val_accuracy: 0.8660\n",
            "Epoch 256/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8637 - val_loss: 0.3260 - val_accuracy: 0.8690\n",
            "Epoch 257/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8699 - val_loss: 0.3278 - val_accuracy: 0.8700\n",
            "Epoch 258/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8749 - val_loss: 0.3282 - val_accuracy: 0.8670\n",
            "Epoch 259/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8709 - val_loss: 0.3261 - val_accuracy: 0.8705\n",
            "Epoch 260/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8649 - val_loss: 0.3264 - val_accuracy: 0.8670\n",
            "Epoch 261/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8674 - val_loss: 0.3259 - val_accuracy: 0.8680\n",
            "Epoch 262/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8660 - val_loss: 0.3280 - val_accuracy: 0.8660\n",
            "Epoch 263/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8663 - val_loss: 0.3253 - val_accuracy: 0.8700\n",
            "Epoch 264/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8666 - val_loss: 0.3329 - val_accuracy: 0.8675\n",
            "Epoch 265/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8649 - val_loss: 0.3287 - val_accuracy: 0.8640\n",
            "Epoch 266/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8663 - val_loss: 0.3252 - val_accuracy: 0.8695\n",
            "Epoch 267/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8660 - val_loss: 0.3288 - val_accuracy: 0.8710\n",
            "Epoch 268/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8700 - val_loss: 0.3268 - val_accuracy: 0.8680\n",
            "Epoch 269/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8672 - val_loss: 0.3276 - val_accuracy: 0.8690\n",
            "Epoch 270/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8746 - val_loss: 0.3277 - val_accuracy: 0.8700\n",
            "Epoch 271/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8642 - val_loss: 0.3254 - val_accuracy: 0.8695\n",
            "Epoch 272/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8645 - val_loss: 0.3263 - val_accuracy: 0.8685\n",
            "Epoch 273/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8667 - val_loss: 0.3288 - val_accuracy: 0.8655\n",
            "Epoch 274/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8684 - val_loss: 0.3284 - val_accuracy: 0.8675\n",
            "Epoch 275/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8702 - val_loss: 0.3255 - val_accuracy: 0.8715\n",
            "Epoch 276/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8633 - val_loss: 0.3259 - val_accuracy: 0.8710\n",
            "Epoch 277/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8691 - val_loss: 0.3265 - val_accuracy: 0.8705\n",
            "Epoch 278/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8702 - val_loss: 0.3262 - val_accuracy: 0.8695\n",
            "Epoch 279/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8601 - val_loss: 0.3280 - val_accuracy: 0.8680\n",
            "Epoch 280/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8671 - val_loss: 0.3273 - val_accuracy: 0.8685\n",
            "Epoch 281/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8703 - val_loss: 0.3281 - val_accuracy: 0.8660\n",
            "Epoch 282/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8634 - val_loss: 0.3265 - val_accuracy: 0.8680\n",
            "Epoch 283/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8689 - val_loss: 0.3288 - val_accuracy: 0.8685\n",
            "Epoch 284/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3176 - accuracy: 0.8697 - val_loss: 0.3264 - val_accuracy: 0.8690\n",
            "Epoch 285/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8702 - val_loss: 0.3258 - val_accuracy: 0.8670\n",
            "Epoch 286/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8686 - val_loss: 0.3263 - val_accuracy: 0.8720\n",
            "Epoch 287/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8664 - val_loss: 0.3272 - val_accuracy: 0.8690\n",
            "Epoch 288/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8641 - val_loss: 0.3253 - val_accuracy: 0.8705\n",
            "Epoch 289/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8647 - val_loss: 0.3268 - val_accuracy: 0.8700\n",
            "Epoch 290/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8677 - val_loss: 0.3273 - val_accuracy: 0.8685\n",
            "Epoch 291/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8677 - val_loss: 0.3279 - val_accuracy: 0.8670\n",
            "Epoch 292/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8694 - val_loss: 0.3288 - val_accuracy: 0.8675\n",
            "Epoch 293/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8735 - val_loss: 0.3250 - val_accuracy: 0.8685\n",
            "Epoch 294/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8653 - val_loss: 0.3266 - val_accuracy: 0.8670\n",
            "Epoch 295/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8686 - val_loss: 0.3261 - val_accuracy: 0.8680\n",
            "Epoch 296/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8678 - val_loss: 0.3286 - val_accuracy: 0.8665\n",
            "Epoch 297/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8729 - val_loss: 0.3272 - val_accuracy: 0.8700\n",
            "Epoch 298/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8651 - val_loss: 0.3268 - val_accuracy: 0.8695\n",
            "Epoch 299/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8647 - val_loss: 0.3271 - val_accuracy: 0.8690\n",
            "Epoch 300/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8624 - val_loss: 0.3271 - val_accuracy: 0.8730\n",
            "Epoch 301/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8649 - val_loss: 0.3281 - val_accuracy: 0.8655\n",
            "Epoch 302/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8727 - val_loss: 0.3263 - val_accuracy: 0.8710\n",
            "Epoch 303/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8722 - val_loss: 0.3267 - val_accuracy: 0.8705\n",
            "Epoch 304/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8617 - val_loss: 0.3308 - val_accuracy: 0.8640\n",
            "Epoch 305/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8773 - val_loss: 0.3263 - val_accuracy: 0.8665\n",
            "Epoch 306/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8663 - val_loss: 0.3289 - val_accuracy: 0.8660\n",
            "Epoch 307/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8661 - val_loss: 0.3320 - val_accuracy: 0.8645\n",
            "Epoch 308/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8696 - val_loss: 0.3264 - val_accuracy: 0.8685\n",
            "Epoch 309/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8664 - val_loss: 0.3276 - val_accuracy: 0.8680\n",
            "Epoch 310/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8700 - val_loss: 0.3296 - val_accuracy: 0.8665\n",
            "Epoch 311/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8714 - val_loss: 0.3269 - val_accuracy: 0.8705\n",
            "Epoch 312/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8681 - val_loss: 0.3266 - val_accuracy: 0.8665\n",
            "Epoch 313/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8733 - val_loss: 0.3277 - val_accuracy: 0.8685\n",
            "Epoch 314/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8691 - val_loss: 0.3270 - val_accuracy: 0.8700\n",
            "Epoch 315/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8611 - val_loss: 0.3267 - val_accuracy: 0.8690\n",
            "Epoch 316/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8662 - val_loss: 0.3297 - val_accuracy: 0.8680\n",
            "Epoch 317/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8637 - val_loss: 0.3271 - val_accuracy: 0.8680\n",
            "Epoch 318/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8688 - val_loss: 0.3301 - val_accuracy: 0.8670\n",
            "Epoch 319/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8625 - val_loss: 0.3313 - val_accuracy: 0.8670\n",
            "Epoch 320/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8602 - val_loss: 0.3279 - val_accuracy: 0.8670\n",
            "Epoch 321/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8671 - val_loss: 0.3303 - val_accuracy: 0.8665\n",
            "Epoch 322/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8679 - val_loss: 0.3269 - val_accuracy: 0.8660\n",
            "Epoch 323/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8649 - val_loss: 0.3317 - val_accuracy: 0.8660\n",
            "Epoch 324/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8692 - val_loss: 0.3296 - val_accuracy: 0.8670\n",
            "Epoch 325/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8624 - val_loss: 0.3274 - val_accuracy: 0.8680\n",
            "Epoch 326/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8657 - val_loss: 0.3270 - val_accuracy: 0.8695\n",
            "Epoch 327/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8624 - val_loss: 0.3270 - val_accuracy: 0.8685\n",
            "Epoch 328/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8680 - val_loss: 0.3289 - val_accuracy: 0.8680\n",
            "Epoch 329/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8638 - val_loss: 0.3294 - val_accuracy: 0.8660\n",
            "Epoch 330/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8690 - val_loss: 0.3288 - val_accuracy: 0.8675\n",
            "Epoch 331/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8712 - val_loss: 0.3286 - val_accuracy: 0.8670\n",
            "Epoch 332/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8654 - val_loss: 0.3290 - val_accuracy: 0.8685\n",
            "Epoch 333/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8597 - val_loss: 0.3311 - val_accuracy: 0.8695\n",
            "Epoch 334/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8642 - val_loss: 0.3288 - val_accuracy: 0.8660\n",
            "Epoch 335/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8684 - val_loss: 0.3285 - val_accuracy: 0.8670\n",
            "Epoch 336/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8722 - val_loss: 0.3272 - val_accuracy: 0.8695\n",
            "Epoch 337/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8617 - val_loss: 0.3281 - val_accuracy: 0.8700\n",
            "Epoch 338/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8653 - val_loss: 0.3279 - val_accuracy: 0.8690\n",
            "Epoch 339/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8654 - val_loss: 0.3282 - val_accuracy: 0.8675\n",
            "Epoch 340/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8724 - val_loss: 0.3281 - val_accuracy: 0.8700\n",
            "Epoch 341/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8701 - val_loss: 0.3290 - val_accuracy: 0.8670\n",
            "Epoch 342/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8638 - val_loss: 0.3296 - val_accuracy: 0.8685\n",
            "Epoch 343/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8723 - val_loss: 0.3281 - val_accuracy: 0.8645\n",
            "Epoch 344/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8734 - val_loss: 0.3281 - val_accuracy: 0.8695\n",
            "Epoch 345/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8662 - val_loss: 0.3288 - val_accuracy: 0.8670\n",
            "Epoch 346/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8679 - val_loss: 0.3284 - val_accuracy: 0.8670\n",
            "Epoch 347/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8704 - val_loss: 0.3285 - val_accuracy: 0.8705\n",
            "Epoch 348/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8689 - val_loss: 0.3277 - val_accuracy: 0.8685\n",
            "Epoch 349/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8677 - val_loss: 0.3279 - val_accuracy: 0.8675\n",
            "Epoch 350/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8647 - val_loss: 0.3292 - val_accuracy: 0.8640\n",
            "Epoch 351/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8679 - val_loss: 0.3305 - val_accuracy: 0.8680\n",
            "Epoch 352/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8722 - val_loss: 0.3301 - val_accuracy: 0.8670\n",
            "Epoch 353/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8655 - val_loss: 0.3288 - val_accuracy: 0.8695\n",
            "Epoch 354/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8698 - val_loss: 0.3278 - val_accuracy: 0.8690\n",
            "Epoch 355/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8682 - val_loss: 0.3301 - val_accuracy: 0.8665\n",
            "Epoch 356/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8663 - val_loss: 0.3290 - val_accuracy: 0.8675\n",
            "Epoch 357/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8543 - val_loss: 0.3286 - val_accuracy: 0.8690\n",
            "Epoch 358/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8683 - val_loss: 0.3369 - val_accuracy: 0.8635\n",
            "Epoch 359/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8698 - val_loss: 0.3315 - val_accuracy: 0.8660\n",
            "Epoch 360/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8657 - val_loss: 0.3312 - val_accuracy: 0.8660\n",
            "Epoch 361/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8666 - val_loss: 0.3324 - val_accuracy: 0.8670\n",
            "Epoch 362/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8685 - val_loss: 0.3286 - val_accuracy: 0.8675\n",
            "Epoch 363/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8648 - val_loss: 0.3301 - val_accuracy: 0.8705\n",
            "Epoch 364/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8715 - val_loss: 0.3289 - val_accuracy: 0.8690\n",
            "Epoch 365/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8702 - val_loss: 0.3299 - val_accuracy: 0.8650\n",
            "Epoch 366/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8667 - val_loss: 0.3295 - val_accuracy: 0.8685\n",
            "Epoch 367/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8632 - val_loss: 0.3311 - val_accuracy: 0.8665\n",
            "Epoch 368/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8717 - val_loss: 0.3305 - val_accuracy: 0.8710\n",
            "Epoch 369/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8748 - val_loss: 0.3295 - val_accuracy: 0.8695\n",
            "Epoch 370/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8677 - val_loss: 0.3294 - val_accuracy: 0.8680\n",
            "Epoch 371/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8707 - val_loss: 0.3309 - val_accuracy: 0.8680\n",
            "Epoch 372/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8649 - val_loss: 0.3304 - val_accuracy: 0.8680\n",
            "Epoch 373/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8753 - val_loss: 0.3286 - val_accuracy: 0.8695\n",
            "Epoch 374/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8690 - val_loss: 0.3318 - val_accuracy: 0.8675\n",
            "Epoch 375/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8676 - val_loss: 0.3293 - val_accuracy: 0.8675\n",
            "Epoch 376/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8671 - val_loss: 0.3334 - val_accuracy: 0.8670\n",
            "Epoch 377/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8706 - val_loss: 0.3319 - val_accuracy: 0.8665\n",
            "Epoch 378/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8675 - val_loss: 0.3306 - val_accuracy: 0.8690\n",
            "Epoch 379/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8679 - val_loss: 0.3369 - val_accuracy: 0.8615\n",
            "Epoch 380/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8647 - val_loss: 0.3309 - val_accuracy: 0.8670\n",
            "Epoch 381/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8696 - val_loss: 0.3333 - val_accuracy: 0.8660\n",
            "Epoch 382/600\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8685 - val_loss: 0.3309 - val_accuracy: 0.8710\n",
            "Epoch 383/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8641 - val_loss: 0.3303 - val_accuracy: 0.8670\n",
            "Epoch 384/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8600 - val_loss: 0.3310 - val_accuracy: 0.8670\n",
            "Epoch 385/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8628 - val_loss: 0.3297 - val_accuracy: 0.8690\n",
            "Epoch 386/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3168 - accuracy: 0.8714 - val_loss: 0.3338 - val_accuracy: 0.8665\n",
            "Epoch 387/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8723 - val_loss: 0.3316 - val_accuracy: 0.8655\n",
            "Epoch 388/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8743 - val_loss: 0.3298 - val_accuracy: 0.8685\n",
            "Epoch 389/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8664 - val_loss: 0.3311 - val_accuracy: 0.8655\n",
            "Epoch 390/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8688 - val_loss: 0.3302 - val_accuracy: 0.8685\n",
            "Epoch 391/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8676 - val_loss: 0.3308 - val_accuracy: 0.8670\n",
            "Epoch 392/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8695 - val_loss: 0.3315 - val_accuracy: 0.8655\n",
            "Epoch 393/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8649 - val_loss: 0.3314 - val_accuracy: 0.8635\n",
            "Epoch 394/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8756 - val_loss: 0.3311 - val_accuracy: 0.8690\n",
            "Epoch 395/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8664 - val_loss: 0.3303 - val_accuracy: 0.8690\n",
            "Epoch 396/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8685 - val_loss: 0.3308 - val_accuracy: 0.8685\n",
            "Epoch 397/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8709 - val_loss: 0.3326 - val_accuracy: 0.8675\n",
            "Epoch 398/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8712 - val_loss: 0.3306 - val_accuracy: 0.8680\n",
            "Epoch 399/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8682 - val_loss: 0.3307 - val_accuracy: 0.8690\n",
            "Epoch 400/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8599 - val_loss: 0.3293 - val_accuracy: 0.8675\n",
            "Epoch 401/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8723 - val_loss: 0.3322 - val_accuracy: 0.8655\n",
            "Epoch 402/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8706 - val_loss: 0.3320 - val_accuracy: 0.8650\n",
            "Epoch 403/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8697 - val_loss: 0.3302 - val_accuracy: 0.8675\n",
            "Epoch 404/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8688 - val_loss: 0.3298 - val_accuracy: 0.8685\n",
            "Epoch 405/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8678 - val_loss: 0.3304 - val_accuracy: 0.8685\n",
            "Epoch 406/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8692 - val_loss: 0.3324 - val_accuracy: 0.8675\n",
            "Epoch 407/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8706 - val_loss: 0.3399 - val_accuracy: 0.8560\n",
            "Epoch 408/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8649 - val_loss: 0.3324 - val_accuracy: 0.8675\n",
            "Epoch 409/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8663 - val_loss: 0.3314 - val_accuracy: 0.8695\n",
            "Epoch 410/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8659 - val_loss: 0.3313 - val_accuracy: 0.8685\n",
            "Epoch 411/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8648 - val_loss: 0.3303 - val_accuracy: 0.8675\n",
            "Epoch 412/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8652 - val_loss: 0.3308 - val_accuracy: 0.8690\n",
            "Epoch 413/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8673 - val_loss: 0.3345 - val_accuracy: 0.8630\n",
            "Epoch 414/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8720 - val_loss: 0.3316 - val_accuracy: 0.8665\n",
            "Epoch 415/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8727 - val_loss: 0.3312 - val_accuracy: 0.8655\n",
            "Epoch 416/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8646 - val_loss: 0.3342 - val_accuracy: 0.8630\n",
            "Epoch 417/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8680 - val_loss: 0.3304 - val_accuracy: 0.8685\n",
            "Epoch 418/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8678 - val_loss: 0.3328 - val_accuracy: 0.8660\n",
            "Epoch 419/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8706 - val_loss: 0.3338 - val_accuracy: 0.8635\n",
            "Epoch 420/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8665 - val_loss: 0.3305 - val_accuracy: 0.8690\n",
            "Epoch 421/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8660 - val_loss: 0.3343 - val_accuracy: 0.8645\n",
            "Epoch 422/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8728 - val_loss: 0.3324 - val_accuracy: 0.8695\n",
            "Epoch 423/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8721 - val_loss: 0.3327 - val_accuracy: 0.8700\n",
            "Epoch 424/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8685 - val_loss: 0.3313 - val_accuracy: 0.8690\n",
            "Epoch 425/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8683 - val_loss: 0.3353 - val_accuracy: 0.8660\n",
            "Epoch 426/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8694 - val_loss: 0.3317 - val_accuracy: 0.8680\n",
            "Epoch 427/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8655 - val_loss: 0.3331 - val_accuracy: 0.8690\n",
            "Epoch 428/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8666 - val_loss: 0.3331 - val_accuracy: 0.8670\n",
            "Epoch 429/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8654 - val_loss: 0.3320 - val_accuracy: 0.8695\n",
            "Epoch 430/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8753 - val_loss: 0.3340 - val_accuracy: 0.8640\n",
            "Epoch 431/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8726 - val_loss: 0.3332 - val_accuracy: 0.8665\n",
            "Epoch 432/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8657 - val_loss: 0.3333 - val_accuracy: 0.8675\n",
            "Epoch 433/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8658 - val_loss: 0.3312 - val_accuracy: 0.8665\n",
            "Epoch 434/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8726 - val_loss: 0.3328 - val_accuracy: 0.8645\n",
            "Epoch 435/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8634 - val_loss: 0.3341 - val_accuracy: 0.8680\n",
            "Epoch 436/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8717 - val_loss: 0.3322 - val_accuracy: 0.8690\n",
            "Epoch 437/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8696 - val_loss: 0.3317 - val_accuracy: 0.8710\n",
            "Epoch 438/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8652 - val_loss: 0.3321 - val_accuracy: 0.8695\n",
            "Epoch 439/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8666 - val_loss: 0.3333 - val_accuracy: 0.8680\n",
            "Epoch 440/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8701 - val_loss: 0.3340 - val_accuracy: 0.8680\n",
            "Epoch 441/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8682 - val_loss: 0.3333 - val_accuracy: 0.8675\n",
            "Epoch 442/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8714 - val_loss: 0.3308 - val_accuracy: 0.8685\n",
            "Epoch 443/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8714 - val_loss: 0.3330 - val_accuracy: 0.8685\n",
            "Epoch 444/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8655 - val_loss: 0.3320 - val_accuracy: 0.8700\n",
            "Epoch 445/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8688 - val_loss: 0.3335 - val_accuracy: 0.8685\n",
            "Epoch 446/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8671 - val_loss: 0.3331 - val_accuracy: 0.8670\n",
            "Epoch 447/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8686 - val_loss: 0.3337 - val_accuracy: 0.8680\n",
            "Epoch 448/600\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3117 - accuracy: 0.8751 - val_loss: 0.3377 - val_accuracy: 0.8650\n",
            "Epoch 449/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8656 - val_loss: 0.3346 - val_accuracy: 0.8640\n",
            "Epoch 450/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8717 - val_loss: 0.3338 - val_accuracy: 0.8665\n",
            "Epoch 451/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8656 - val_loss: 0.3336 - val_accuracy: 0.8660\n",
            "Epoch 452/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8668 - val_loss: 0.3396 - val_accuracy: 0.8620\n",
            "Epoch 453/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8695 - val_loss: 0.3348 - val_accuracy: 0.8625\n",
            "Epoch 454/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8786 - val_loss: 0.3338 - val_accuracy: 0.8645\n",
            "Epoch 455/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8646 - val_loss: 0.3325 - val_accuracy: 0.8675\n",
            "Epoch 456/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8656 - val_loss: 0.3337 - val_accuracy: 0.8665\n",
            "Epoch 457/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8657 - val_loss: 0.3332 - val_accuracy: 0.8660\n",
            "Epoch 458/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8719 - val_loss: 0.3322 - val_accuracy: 0.8715\n",
            "Epoch 459/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8646 - val_loss: 0.3324 - val_accuracy: 0.8685\n",
            "Epoch 460/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8656 - val_loss: 0.3350 - val_accuracy: 0.8675\n",
            "Epoch 461/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8708 - val_loss: 0.3327 - val_accuracy: 0.8690\n",
            "Epoch 462/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8656 - val_loss: 0.3335 - val_accuracy: 0.8680\n",
            "Epoch 463/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8663 - val_loss: 0.3331 - val_accuracy: 0.8665\n",
            "Epoch 464/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8601 - val_loss: 0.3370 - val_accuracy: 0.8590\n",
            "Epoch 465/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8708 - val_loss: 0.3343 - val_accuracy: 0.8665\n",
            "Epoch 466/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8662 - val_loss: 0.3331 - val_accuracy: 0.8660\n",
            "Epoch 467/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8704 - val_loss: 0.3312 - val_accuracy: 0.8675\n",
            "Epoch 468/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3097 - accuracy: 0.8738 - val_loss: 0.3319 - val_accuracy: 0.8710\n",
            "Epoch 469/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8762 - val_loss: 0.3391 - val_accuracy: 0.8640\n",
            "Epoch 470/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8749 - val_loss: 0.3328 - val_accuracy: 0.8660\n",
            "Epoch 471/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8712 - val_loss: 0.3333 - val_accuracy: 0.8675\n",
            "Epoch 472/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8756 - val_loss: 0.3320 - val_accuracy: 0.8670\n",
            "Epoch 473/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8736 - val_loss: 0.3333 - val_accuracy: 0.8660\n",
            "Epoch 474/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8671 - val_loss: 0.3320 - val_accuracy: 0.8685\n",
            "Epoch 475/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8750 - val_loss: 0.3331 - val_accuracy: 0.8690\n",
            "Epoch 476/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8733 - val_loss: 0.3325 - val_accuracy: 0.8690\n",
            "Epoch 477/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8630 - val_loss: 0.3342 - val_accuracy: 0.8660\n",
            "Epoch 478/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8727 - val_loss: 0.3331 - val_accuracy: 0.8680\n",
            "Epoch 479/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8708 - val_loss: 0.3354 - val_accuracy: 0.8655\n",
            "Epoch 480/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8640 - val_loss: 0.3340 - val_accuracy: 0.8670\n",
            "Epoch 481/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.8668 - val_loss: 0.3355 - val_accuracy: 0.8660\n",
            "Epoch 482/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3126 - accuracy: 0.8726 - val_loss: 0.3346 - val_accuracy: 0.8665\n",
            "Epoch 483/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3149 - accuracy: 0.8691 - val_loss: 0.3338 - val_accuracy: 0.8635\n",
            "Epoch 484/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3249 - accuracy: 0.8660 - val_loss: 0.3329 - val_accuracy: 0.8695\n",
            "Epoch 485/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8637 - val_loss: 0.3317 - val_accuracy: 0.8675\n",
            "Epoch 486/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3200 - accuracy: 0.8683 - val_loss: 0.3328 - val_accuracy: 0.8690\n",
            "Epoch 487/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8640 - val_loss: 0.3323 - val_accuracy: 0.8690\n",
            "Epoch 488/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3131 - accuracy: 0.8680 - val_loss: 0.3336 - val_accuracy: 0.8650\n",
            "Epoch 489/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3175 - accuracy: 0.8680 - val_loss: 0.3332 - val_accuracy: 0.8680\n",
            "Epoch 490/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8710 - val_loss: 0.3338 - val_accuracy: 0.8675\n",
            "Epoch 491/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8679 - val_loss: 0.3333 - val_accuracy: 0.8670\n",
            "Epoch 492/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8703 - val_loss: 0.3344 - val_accuracy: 0.8690\n",
            "Epoch 493/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8731 - val_loss: 0.3332 - val_accuracy: 0.8700\n",
            "Epoch 494/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8717 - val_loss: 0.3326 - val_accuracy: 0.8720\n",
            "Epoch 495/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8675 - val_loss: 0.3331 - val_accuracy: 0.8665\n",
            "Epoch 496/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8719 - val_loss: 0.3322 - val_accuracy: 0.8635\n",
            "Epoch 497/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8695 - val_loss: 0.3332 - val_accuracy: 0.8680\n",
            "Epoch 498/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8704 - val_loss: 0.3321 - val_accuracy: 0.8660\n",
            "Epoch 499/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8728 - val_loss: 0.3329 - val_accuracy: 0.8685\n",
            "Epoch 500/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8687 - val_loss: 0.3311 - val_accuracy: 0.8680\n",
            "Epoch 501/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.8696 - val_loss: 0.3347 - val_accuracy: 0.8670\n",
            "Epoch 502/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8729 - val_loss: 0.3327 - val_accuracy: 0.8675\n",
            "Epoch 503/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8673 - val_loss: 0.3324 - val_accuracy: 0.8690\n",
            "Epoch 504/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8662 - val_loss: 0.3325 - val_accuracy: 0.8670\n",
            "Epoch 505/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8693 - val_loss: 0.3319 - val_accuracy: 0.8665\n",
            "Epoch 506/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8755 - val_loss: 0.3331 - val_accuracy: 0.8670\n",
            "Epoch 507/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8718 - val_loss: 0.3311 - val_accuracy: 0.8650\n",
            "Epoch 508/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8673 - val_loss: 0.3327 - val_accuracy: 0.8675\n",
            "Epoch 509/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8641 - val_loss: 0.3325 - val_accuracy: 0.8685\n",
            "Epoch 510/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8737 - val_loss: 0.3324 - val_accuracy: 0.8680\n",
            "Epoch 511/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8711 - val_loss: 0.3327 - val_accuracy: 0.8660\n",
            "Epoch 512/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8763 - val_loss: 0.3394 - val_accuracy: 0.8645\n",
            "Epoch 513/600\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3150 - accuracy: 0.8704 - val_loss: 0.3337 - val_accuracy: 0.8650\n",
            "Epoch 514/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8746 - val_loss: 0.3328 - val_accuracy: 0.8675\n",
            "Epoch 515/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8703 - val_loss: 0.3359 - val_accuracy: 0.8705\n",
            "Epoch 516/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8670 - val_loss: 0.3333 - val_accuracy: 0.8670\n",
            "Epoch 517/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8750 - val_loss: 0.3321 - val_accuracy: 0.8665\n",
            "Epoch 518/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8698 - val_loss: 0.3326 - val_accuracy: 0.8675\n",
            "Epoch 519/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8711 - val_loss: 0.3317 - val_accuracy: 0.8685\n",
            "Epoch 520/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8694 - val_loss: 0.3335 - val_accuracy: 0.8670\n",
            "Epoch 521/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8653 - val_loss: 0.3347 - val_accuracy: 0.8665\n",
            "Epoch 522/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8730 - val_loss: 0.3319 - val_accuracy: 0.8695\n",
            "Epoch 523/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8657 - val_loss: 0.3404 - val_accuracy: 0.8665\n",
            "Epoch 524/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3073 - accuracy: 0.8754 - val_loss: 0.3320 - val_accuracy: 0.8690\n",
            "Epoch 525/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8697 - val_loss: 0.3334 - val_accuracy: 0.8640\n",
            "Epoch 526/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8722 - val_loss: 0.3334 - val_accuracy: 0.8660\n",
            "Epoch 527/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8676 - val_loss: 0.3331 - val_accuracy: 0.8685\n",
            "Epoch 528/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8738 - val_loss: 0.3327 - val_accuracy: 0.8665\n",
            "Epoch 529/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8686 - val_loss: 0.3376 - val_accuracy: 0.8625\n",
            "Epoch 530/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8695 - val_loss: 0.3334 - val_accuracy: 0.8660\n",
            "Epoch 531/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8706 - val_loss: 0.3353 - val_accuracy: 0.8665\n",
            "Epoch 532/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8720 - val_loss: 0.3340 - val_accuracy: 0.8665\n",
            "Epoch 533/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8701 - val_loss: 0.3368 - val_accuracy: 0.8670\n",
            "Epoch 534/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8727 - val_loss: 0.3345 - val_accuracy: 0.8660\n",
            "Epoch 535/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8732 - val_loss: 0.3324 - val_accuracy: 0.8675\n",
            "Epoch 536/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8614 - val_loss: 0.3367 - val_accuracy: 0.8665\n",
            "Epoch 537/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8662 - val_loss: 0.3332 - val_accuracy: 0.8680\n",
            "Epoch 538/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3173 - accuracy: 0.8648 - val_loss: 0.3358 - val_accuracy: 0.8640\n",
            "Epoch 539/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8648 - val_loss: 0.3343 - val_accuracy: 0.8685\n",
            "Epoch 540/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8737 - val_loss: 0.3384 - val_accuracy: 0.8645\n",
            "Epoch 541/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8611 - val_loss: 0.3328 - val_accuracy: 0.8675\n",
            "Epoch 542/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8692 - val_loss: 0.3349 - val_accuracy: 0.8675\n",
            "Epoch 543/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8690 - val_loss: 0.3320 - val_accuracy: 0.8685\n",
            "Epoch 544/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8731 - val_loss: 0.3331 - val_accuracy: 0.8700\n",
            "Epoch 545/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8650 - val_loss: 0.3336 - val_accuracy: 0.8705\n",
            "Epoch 546/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8633 - val_loss: 0.3335 - val_accuracy: 0.8655\n",
            "Epoch 547/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8627 - val_loss: 0.3397 - val_accuracy: 0.8665\n",
            "Epoch 548/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8687 - val_loss: 0.3338 - val_accuracy: 0.8685\n",
            "Epoch 549/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8749 - val_loss: 0.3366 - val_accuracy: 0.8640\n",
            "Epoch 550/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8710 - val_loss: 0.3341 - val_accuracy: 0.8670\n",
            "Epoch 551/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8604 - val_loss: 0.3338 - val_accuracy: 0.8670\n",
            "Epoch 552/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8704 - val_loss: 0.3336 - val_accuracy: 0.8670\n",
            "Epoch 553/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8754 - val_loss: 0.3354 - val_accuracy: 0.8680\n",
            "Epoch 554/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8708 - val_loss: 0.3358 - val_accuracy: 0.8685\n",
            "Epoch 555/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8702 - val_loss: 0.3357 - val_accuracy: 0.8680\n",
            "Epoch 556/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8658 - val_loss: 0.3355 - val_accuracy: 0.8665\n",
            "Epoch 557/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8663 - val_loss: 0.3331 - val_accuracy: 0.8685\n",
            "Epoch 558/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8631 - val_loss: 0.3335 - val_accuracy: 0.8665\n",
            "Epoch 559/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8669 - val_loss: 0.3352 - val_accuracy: 0.8675\n",
            "Epoch 560/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8712 - val_loss: 0.3343 - val_accuracy: 0.8665\n",
            "Epoch 561/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8710 - val_loss: 0.3342 - val_accuracy: 0.8640\n",
            "Epoch 562/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8642 - val_loss: 0.3341 - val_accuracy: 0.8660\n",
            "Epoch 563/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8674 - val_loss: 0.3342 - val_accuracy: 0.8685\n",
            "Epoch 564/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8753 - val_loss: 0.3366 - val_accuracy: 0.8700\n",
            "Epoch 565/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8694 - val_loss: 0.3379 - val_accuracy: 0.8625\n",
            "Epoch 566/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8687 - val_loss: 0.3357 - val_accuracy: 0.8655\n",
            "Epoch 567/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8775 - val_loss: 0.3352 - val_accuracy: 0.8650\n",
            "Epoch 568/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8726 - val_loss: 0.3387 - val_accuracy: 0.8680\n",
            "Epoch 569/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8696 - val_loss: 0.3338 - val_accuracy: 0.8705\n",
            "Epoch 570/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8672 - val_loss: 0.3366 - val_accuracy: 0.8675\n",
            "Epoch 571/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8690 - val_loss: 0.3346 - val_accuracy: 0.8660\n",
            "Epoch 572/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8671 - val_loss: 0.3336 - val_accuracy: 0.8670\n",
            "Epoch 573/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8717 - val_loss: 0.3336 - val_accuracy: 0.8670\n",
            "Epoch 574/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8680 - val_loss: 0.3336 - val_accuracy: 0.8670\n",
            "Epoch 575/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8691 - val_loss: 0.3360 - val_accuracy: 0.8710\n",
            "Epoch 576/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8720 - val_loss: 0.3333 - val_accuracy: 0.8670\n",
            "Epoch 577/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8671 - val_loss: 0.3350 - val_accuracy: 0.8705\n",
            "Epoch 578/600\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3154 - accuracy: 0.8712 - val_loss: 0.3330 - val_accuracy: 0.8685\n",
            "Epoch 579/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8714 - val_loss: 0.3364 - val_accuracy: 0.8670\n",
            "Epoch 580/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8723 - val_loss: 0.3328 - val_accuracy: 0.8670\n",
            "Epoch 581/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8679 - val_loss: 0.3333 - val_accuracy: 0.8660\n",
            "Epoch 582/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8624 - val_loss: 0.3388 - val_accuracy: 0.8630\n",
            "Epoch 583/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8712 - val_loss: 0.3374 - val_accuracy: 0.8630\n",
            "Epoch 584/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8688 - val_loss: 0.3355 - val_accuracy: 0.8675\n",
            "Epoch 585/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8741 - val_loss: 0.3396 - val_accuracy: 0.8635\n",
            "Epoch 586/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8726 - val_loss: 0.3394 - val_accuracy: 0.8690\n",
            "Epoch 587/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8654 - val_loss: 0.3360 - val_accuracy: 0.8625\n",
            "Epoch 588/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8734 - val_loss: 0.3339 - val_accuracy: 0.8635\n",
            "Epoch 589/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8718 - val_loss: 0.3342 - val_accuracy: 0.8665\n",
            "Epoch 590/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8736 - val_loss: 0.3345 - val_accuracy: 0.8660\n",
            "Epoch 591/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8644 - val_loss: 0.3353 - val_accuracy: 0.8645\n",
            "Epoch 592/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8715 - val_loss: 0.3338 - val_accuracy: 0.8665\n",
            "Epoch 593/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8654 - val_loss: 0.3390 - val_accuracy: 0.8625\n",
            "Epoch 594/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8636 - val_loss: 0.3342 - val_accuracy: 0.8650\n",
            "Epoch 595/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8718 - val_loss: 0.3375 - val_accuracy: 0.8650\n",
            "Epoch 596/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8679 - val_loss: 0.3401 - val_accuracy: 0.8650\n",
            "Epoch 597/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8672 - val_loss: 0.3344 - val_accuracy: 0.8670\n",
            "Epoch 598/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8704 - val_loss: 0.3342 - val_accuracy: 0.8670\n",
            "Epoch 599/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8770 - val_loss: 0.3481 - val_accuracy: 0.8650\n",
            "Epoch 600/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8677 - val_loss: 0.3343 - val_accuracy: 0.8680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbb26b21f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzygFzIygbiE"
      },
      "source": [
        "#model's history\r\n",
        "model_loss = pd.DataFrame(model.history.history)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "qKeEqU86giI7",
        "outputId": "4a47ea45-22f4-40c6-ecb6-120b00e608b1"
      },
      "source": [
        "#model loss\r\n",
        "model_loss.plot()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbae53ab358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "8uboqhPOlxVG",
        "outputId": "3d461de3-83a8-4c27-a52d-12c36a631f58"
      },
      "source": [
        "# These are predicted probabilities\r\n",
        "y_predicted = model.predict(X_test)\r\n",
        "# Convert Predicted probabilities into binary outcome\r\n",
        "y_predicted = (y_predicted > 0.5)\r\n",
        "print(np.concatenate((y_predicted.reshape(len(y_predicted),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-5256bd7b4d9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert Predicted probabilities into binary outcome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_predicted\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxchIaDNjykw"
      },
      "source": [
        "# Predicting the Test set results\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "y_pred = (y_pred > 0.5)\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "cm = confusion_matrix(y_test, y_predicted)\r\n",
        "print(cm)\r\n",
        "accuracy_score(y_test, y_predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6i7TCE7nUwT"
      },
      "source": [
        "**Accuracy of Method 1=> 0.867**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xta9raSbhFDO"
      },
      "source": [
        "**METHOD 2: CONSIDERING EARLY STOPPING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykij9HNYg_iP"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa67WVfAg9w_"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(units=30,activation='relu'))\r\n",
        "model.add(Dense(units=15,activation='relu'))\r\n",
        "model.add(Dense(units=1,activation='sigmoid'))\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z47ntNh3hsPx"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-srJsyPyhsML",
        "outputId": "21fcc63f-565d-42b3-f28b-1263ae3a53f2"
      },
      "source": [
        "%%time\r\n",
        "model.fit(x=X_train, \r\n",
        "          y=y_train, \r\n",
        "          epochs=600,\r\n",
        "          validation_data=(X_test, y_test), verbose=1,\r\n",
        "          callbacks=[early_stop]\r\n",
        "          )"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.8017 - val_loss: 0.4620 - val_accuracy: 0.7970\n",
            "Epoch 2/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8010 - val_loss: 0.4380 - val_accuracy: 0.8085\n",
            "Epoch 3/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8165 - val_loss: 0.4233 - val_accuracy: 0.8130\n",
            "Epoch 4/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8239 - val_loss: 0.4185 - val_accuracy: 0.8235\n",
            "Epoch 5/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8200 - val_loss: 0.4063 - val_accuracy: 0.8250\n",
            "Epoch 6/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8343 - val_loss: 0.3954 - val_accuracy: 0.8325\n",
            "Epoch 7/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8328 - val_loss: 0.3858 - val_accuracy: 0.8330\n",
            "Epoch 8/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8378 - val_loss: 0.3756 - val_accuracy: 0.8385\n",
            "Epoch 9/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8398 - val_loss: 0.3638 - val_accuracy: 0.8450\n",
            "Epoch 10/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8406 - val_loss: 0.3581 - val_accuracy: 0.8485\n",
            "Epoch 11/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8466 - val_loss: 0.3551 - val_accuracy: 0.8565\n",
            "Epoch 12/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8529 - val_loss: 0.3542 - val_accuracy: 0.8525\n",
            "Epoch 13/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8511 - val_loss: 0.3521 - val_accuracy: 0.8550\n",
            "Epoch 14/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8571 - val_loss: 0.3451 - val_accuracy: 0.8585\n",
            "Epoch 15/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8534 - val_loss: 0.3439 - val_accuracy: 0.8545\n",
            "Epoch 16/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8562 - val_loss: 0.3439 - val_accuracy: 0.8530\n",
            "Epoch 17/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8564 - val_loss: 0.3432 - val_accuracy: 0.8550\n",
            "Epoch 18/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8511 - val_loss: 0.3405 - val_accuracy: 0.8545\n",
            "Epoch 19/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8580 - val_loss: 0.3434 - val_accuracy: 0.8525\n",
            "Epoch 20/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8543 - val_loss: 0.3391 - val_accuracy: 0.8585\n",
            "Epoch 21/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8651 - val_loss: 0.3397 - val_accuracy: 0.8560\n",
            "Epoch 22/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8641 - val_loss: 0.3367 - val_accuracy: 0.8585\n",
            "Epoch 23/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8619 - val_loss: 0.3381 - val_accuracy: 0.8615\n",
            "Epoch 24/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8611 - val_loss: 0.3380 - val_accuracy: 0.8605\n",
            "Epoch 25/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8595 - val_loss: 0.3348 - val_accuracy: 0.8595\n",
            "Epoch 26/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8576 - val_loss: 0.3366 - val_accuracy: 0.8570\n",
            "Epoch 27/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8572 - val_loss: 0.3368 - val_accuracy: 0.8580\n",
            "Epoch 28/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8586 - val_loss: 0.3358 - val_accuracy: 0.8595\n",
            "Epoch 29/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8620 - val_loss: 0.3393 - val_accuracy: 0.8575\n",
            "Epoch 30/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8593 - val_loss: 0.3354 - val_accuracy: 0.8585\n",
            "Epoch 31/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8586 - val_loss: 0.3367 - val_accuracy: 0.8565\n",
            "Epoch 32/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8565 - val_loss: 0.3342 - val_accuracy: 0.8605\n",
            "Epoch 33/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8635 - val_loss: 0.3339 - val_accuracy: 0.8605\n",
            "Epoch 34/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8693 - val_loss: 0.3358 - val_accuracy: 0.8585\n",
            "Epoch 35/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8627 - val_loss: 0.3356 - val_accuracy: 0.8600\n",
            "Epoch 36/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8555 - val_loss: 0.3352 - val_accuracy: 0.8595\n",
            "Epoch 37/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8592 - val_loss: 0.3323 - val_accuracy: 0.8625\n",
            "Epoch 38/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8615 - val_loss: 0.3339 - val_accuracy: 0.8570\n",
            "Epoch 39/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8595 - val_loss: 0.3328 - val_accuracy: 0.8615\n",
            "Epoch 40/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8622 - val_loss: 0.3342 - val_accuracy: 0.8595\n",
            "Epoch 41/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8586 - val_loss: 0.3409 - val_accuracy: 0.8590\n",
            "Epoch 42/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8603 - val_loss: 0.3333 - val_accuracy: 0.8625\n",
            "Epoch 43/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8595 - val_loss: 0.3322 - val_accuracy: 0.8645\n",
            "Epoch 44/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8624 - val_loss: 0.3335 - val_accuracy: 0.8600\n",
            "Epoch 45/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8555 - val_loss: 0.3330 - val_accuracy: 0.8635\n",
            "Epoch 46/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8578 - val_loss: 0.3355 - val_accuracy: 0.8585\n",
            "Epoch 47/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8611 - val_loss: 0.3400 - val_accuracy: 0.8580\n",
            "Epoch 48/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8653 - val_loss: 0.3320 - val_accuracy: 0.8630\n",
            "Epoch 49/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8644 - val_loss: 0.3314 - val_accuracy: 0.8635\n",
            "Epoch 50/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8619 - val_loss: 0.3317 - val_accuracy: 0.8635\n",
            "Epoch 51/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8627 - val_loss: 0.3306 - val_accuracy: 0.8625\n",
            "Epoch 52/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8636 - val_loss: 0.3315 - val_accuracy: 0.8605\n",
            "Epoch 53/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8550 - val_loss: 0.3315 - val_accuracy: 0.8620\n",
            "Epoch 54/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8516 - val_loss: 0.3292 - val_accuracy: 0.8630\n",
            "Epoch 55/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8619 - val_loss: 0.3301 - val_accuracy: 0.8660\n",
            "Epoch 56/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8623 - val_loss: 0.3314 - val_accuracy: 0.8640\n",
            "Epoch 57/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8616 - val_loss: 0.3352 - val_accuracy: 0.8595\n",
            "Epoch 58/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8668 - val_loss: 0.3340 - val_accuracy: 0.8595\n",
            "Epoch 59/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8697 - val_loss: 0.3284 - val_accuracy: 0.8645\n",
            "Epoch 60/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8632 - val_loss: 0.3305 - val_accuracy: 0.8590\n",
            "Epoch 61/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8656 - val_loss: 0.3305 - val_accuracy: 0.8600\n",
            "Epoch 62/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8614 - val_loss: 0.3316 - val_accuracy: 0.8610\n",
            "Epoch 63/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8622 - val_loss: 0.3299 - val_accuracy: 0.8640\n",
            "Epoch 64/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8609 - val_loss: 0.3361 - val_accuracy: 0.8585\n",
            "Epoch 65/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8563 - val_loss: 0.3302 - val_accuracy: 0.8595\n",
            "Epoch 66/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8543 - val_loss: 0.3443 - val_accuracy: 0.8570\n",
            "Epoch 67/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8610 - val_loss: 0.3297 - val_accuracy: 0.8635\n",
            "Epoch 68/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3380 - accuracy: 0.8618 - val_loss: 0.3304 - val_accuracy: 0.8640\n",
            "Epoch 69/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8612 - val_loss: 0.3314 - val_accuracy: 0.8560\n",
            "Epoch 70/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8615 - val_loss: 0.3305 - val_accuracy: 0.8595\n",
            "Epoch 71/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8650 - val_loss: 0.3371 - val_accuracy: 0.8575\n",
            "Epoch 72/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8584 - val_loss: 0.3301 - val_accuracy: 0.8615\n",
            "Epoch 73/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8565 - val_loss: 0.3306 - val_accuracy: 0.8585\n",
            "Epoch 74/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8657 - val_loss: 0.3340 - val_accuracy: 0.8580\n",
            "Epoch 75/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8618 - val_loss: 0.3291 - val_accuracy: 0.8605\n",
            "Epoch 76/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8599 - val_loss: 0.3291 - val_accuracy: 0.8620\n",
            "Epoch 77/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8676 - val_loss: 0.3314 - val_accuracy: 0.8555\n",
            "Epoch 78/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8633 - val_loss: 0.3283 - val_accuracy: 0.8595\n",
            "Epoch 79/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8678 - val_loss: 0.3338 - val_accuracy: 0.8580\n",
            "Epoch 80/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8541 - val_loss: 0.3317 - val_accuracy: 0.8625\n",
            "Epoch 81/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8581 - val_loss: 0.3287 - val_accuracy: 0.8640\n",
            "Epoch 82/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8657 - val_loss: 0.3285 - val_accuracy: 0.8625\n",
            "Epoch 83/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8624 - val_loss: 0.3338 - val_accuracy: 0.8645\n",
            "Epoch 84/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8655 - val_loss: 0.3307 - val_accuracy: 0.8635\n",
            "Epoch 85/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8644 - val_loss: 0.3285 - val_accuracy: 0.8580\n",
            "Epoch 86/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8643 - val_loss: 0.3299 - val_accuracy: 0.8625\n",
            "Epoch 87/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8689 - val_loss: 0.3284 - val_accuracy: 0.8550\n",
            "Epoch 88/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8651 - val_loss: 0.3298 - val_accuracy: 0.8610\n",
            "Epoch 89/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8589 - val_loss: 0.3278 - val_accuracy: 0.8650\n",
            "Epoch 90/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8646 - val_loss: 0.3314 - val_accuracy: 0.8535\n",
            "Epoch 91/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8633 - val_loss: 0.3279 - val_accuracy: 0.8600\n",
            "Epoch 92/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8648 - val_loss: 0.3277 - val_accuracy: 0.8580\n",
            "Epoch 93/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8675 - val_loss: 0.3320 - val_accuracy: 0.8560\n",
            "Epoch 94/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8604 - val_loss: 0.3307 - val_accuracy: 0.8565\n",
            "Epoch 95/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8681 - val_loss: 0.3278 - val_accuracy: 0.8640\n",
            "Epoch 96/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8712 - val_loss: 0.3328 - val_accuracy: 0.8600\n",
            "Epoch 97/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8653 - val_loss: 0.3279 - val_accuracy: 0.8635\n",
            "Epoch 98/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8641 - val_loss: 0.3294 - val_accuracy: 0.8560\n",
            "Epoch 99/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8593 - val_loss: 0.3283 - val_accuracy: 0.8610\n",
            "Epoch 100/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8645 - val_loss: 0.3295 - val_accuracy: 0.8550\n",
            "Epoch 101/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8734 - val_loss: 0.3329 - val_accuracy: 0.8605\n",
            "Epoch 102/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8648 - val_loss: 0.3342 - val_accuracy: 0.8560\n",
            "Epoch 103/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8639 - val_loss: 0.3275 - val_accuracy: 0.8610\n",
            "Epoch 104/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8689 - val_loss: 0.3282 - val_accuracy: 0.8590\n",
            "Epoch 105/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8675 - val_loss: 0.3318 - val_accuracy: 0.8600\n",
            "Epoch 106/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8698 - val_loss: 0.3298 - val_accuracy: 0.8585\n",
            "Epoch 107/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8661 - val_loss: 0.3298 - val_accuracy: 0.8545\n",
            "Epoch 108/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8693 - val_loss: 0.3269 - val_accuracy: 0.8625\n",
            "Epoch 109/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3156 - accuracy: 0.8712 - val_loss: 0.3283 - val_accuracy: 0.8615\n",
            "Epoch 110/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8662 - val_loss: 0.3290 - val_accuracy: 0.8605\n",
            "Epoch 111/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8675 - val_loss: 0.3326 - val_accuracy: 0.8570\n",
            "Epoch 112/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8619 - val_loss: 0.3298 - val_accuracy: 0.8550\n",
            "Epoch 113/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8737 - val_loss: 0.3310 - val_accuracy: 0.8545\n",
            "Epoch 114/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8658 - val_loss: 0.3294 - val_accuracy: 0.8565\n",
            "Epoch 115/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8703 - val_loss: 0.3353 - val_accuracy: 0.8535\n",
            "Epoch 116/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8680 - val_loss: 0.3280 - val_accuracy: 0.8600\n",
            "Epoch 117/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8658 - val_loss: 0.3293 - val_accuracy: 0.8590\n",
            "Epoch 118/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8739 - val_loss: 0.3292 - val_accuracy: 0.8580\n",
            "Epoch 119/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8654 - val_loss: 0.3285 - val_accuracy: 0.8595\n",
            "Epoch 120/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8706 - val_loss: 0.3285 - val_accuracy: 0.8585\n",
            "Epoch 121/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8693 - val_loss: 0.3330 - val_accuracy: 0.8555\n",
            "Epoch 122/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8640 - val_loss: 0.3304 - val_accuracy: 0.8610\n",
            "Epoch 123/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8722 - val_loss: 0.3304 - val_accuracy: 0.8615\n",
            "Epoch 124/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8604 - val_loss: 0.3287 - val_accuracy: 0.8625\n",
            "Epoch 125/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8643 - val_loss: 0.3339 - val_accuracy: 0.8580\n",
            "Epoch 126/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8702 - val_loss: 0.3285 - val_accuracy: 0.8580\n",
            "Epoch 127/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8585 - val_loss: 0.3281 - val_accuracy: 0.8580\n",
            "Epoch 128/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8587 - val_loss: 0.3280 - val_accuracy: 0.8620\n",
            "Epoch 129/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8672 - val_loss: 0.3302 - val_accuracy: 0.8550\n",
            "Epoch 130/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8656 - val_loss: 0.3340 - val_accuracy: 0.8565\n",
            "Epoch 131/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8676 - val_loss: 0.3311 - val_accuracy: 0.8590\n",
            "Epoch 132/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8649 - val_loss: 0.3317 - val_accuracy: 0.8540\n",
            "Epoch 133/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8638 - val_loss: 0.3300 - val_accuracy: 0.8575\n",
            "Epoch 00133: early stopping\n",
            "CPU times: user 1min 7s, sys: 5.63 s, total: 1min 12s\n",
            "Wall time: 1min 1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbae9714240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwYheXbvnfQb",
        "outputId": "8cd866a5-08e5-4582-806f-47786624120e"
      },
      "source": [
        "\r\n",
        "y_predicted = model.predict(X_test)\r\n",
        "\r\n",
        "y_predicted = (y_predicted > 0.5)\r\n",
        "print(np.concatenate((y_predicted.reshape(len(y_predicted),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBEjhDjmhsJs",
        "outputId": "38d62979-82c2-4b11-a1c4-c012becc1320"
      },
      "source": [
        "# Predicting the Test set results\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "y_pred = (y_pred > 0.5)\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "cm = confusion_matrix(y_test, y_predicted)\r\n",
        "print(cm)\r\n",
        "accuracy_score(y_test, y_predicted)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1493   84]\n",
            " [ 201  222]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px5dXhTkmM8E"
      },
      "source": [
        "**Accuracy in method 2 is 0.8575**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSxnFDThhDYp"
      },
      "source": [
        "**METHOD 3:Adding in DropOut Layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_8uCGG6mcHn"
      },
      "source": [
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEzpxC3Cmj5S"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(units=30,activation='relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "model.add(Dense(units=15,activation='relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "model.add(Dense(units=1,activation='sigmoid'))\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['Accuracy'])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4glOy37znlCb",
        "outputId": "de530a16-46ba-4ee0-d84d-3c487bddbce4"
      },
      "source": [
        "%%time\r\n",
        "model.fit(x=X_train, \r\n",
        "          y=y_train, \r\n",
        "          epochs=600,\r\n",
        "          validation_data=(X_test, y_test), verbose=1,\r\n",
        "          callbacks=[early_stop]\r\n",
        "          )"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.0000e+00 - val_loss: 0.4849 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.0000e+00 - val_loss: 0.4727 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.0000e+00 - val_loss: 0.4686 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.0000e+00 - val_loss: 0.4628 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.0000e+00 - val_loss: 0.4581 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.0000e+00 - val_loss: 0.4529 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.0000e+00 - val_loss: 0.4473 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.0000e+00 - val_loss: 0.4367 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.0000e+00 - val_loss: 0.4315 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.0000e+00 - val_loss: 0.4283 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.0000e+00 - val_loss: 0.4238 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.0000e+00 - val_loss: 0.4165 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.0000e+00 - val_loss: 0.4129 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.0000e+00 - val_loss: 0.4062 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.0000e+00 - val_loss: 0.4036 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.0000e+00 - val_loss: 0.3965 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.0000e+00 - val_loss: 0.3932 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.0000e+00 - val_loss: 0.3860 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.0000e+00 - val_loss: 0.3872 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.0000e+00 - val_loss: 0.3814 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.0000e+00 - val_loss: 0.3814 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.0000e+00 - val_loss: 0.3740 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.0000e+00 - val_loss: 0.3720 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.0000e+00 - val_loss: 0.3722 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.0000e+00 - val_loss: 0.3682 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.0000e+00 - val_loss: 0.3693 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.0000e+00 - val_loss: 0.3657 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4153 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.0000e+00 - val_loss: 0.3623 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.0000e+00 - val_loss: 0.3686 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.0000e+00 - val_loss: 0.3627 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.0000e+00 - val_loss: 0.3631 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.0000e+00 - val_loss: 0.3590 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.0000e+00 - val_loss: 0.3568 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 2.9512e-04 - val_loss: 0.3585 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.0000e+00 - val_loss: 0.3579 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.0000e+00 - val_loss: 0.3601 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 5.7329e-04 - val_loss: 0.3548 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 1.1691e-04 - val_loss: 0.3554 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 4.3133e-04 - val_loss: 0.3565 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.0000e+00 - val_loss: 0.3551 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 3.1271e-04 - val_loss: 0.3538 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 1.8158e-04 - val_loss: 0.3491 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.0000e+00 - val_loss: 0.3497 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 4.4091e-05 - val_loss: 0.3523 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3966 - accuracy: 1.9910e-04 - val_loss: 0.3506 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 5.8214e-04 - val_loss: 0.3500 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 2.1880e-04 - val_loss: 0.3497 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 4.4756e-04 - val_loss: 0.3520 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 5.2343e-04 - val_loss: 0.3480 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.0000e+00 - val_loss: 0.3499 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.0012 - val_loss: 0.3482 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 4.6951e-04 - val_loss: 0.3488 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 4.0890e-04 - val_loss: 0.3432 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 1.7930e-04 - val_loss: 0.3501 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 1.3280e-04 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 1.6322e-04 - val_loss: 0.3474 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 8.9804e-04 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 4.0856e-04 - val_loss: 0.3454 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 6.5606e-04 - val_loss: 0.3442 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 4.9855e-04 - val_loss: 0.3465 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3984 - accuracy: 5.0607e-05 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 9.2647e-05 - val_loss: 0.3440 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 8.1771e-05 - val_loss: 0.3406 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 6.1634e-04 - val_loss: 0.3441 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 8.5178e-04 - val_loss: 0.3421 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.0011 - val_loss: 0.3447 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4029 - accuracy: 3.1612e-04 - val_loss: 0.3403 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 3.6104e-04 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3836 - accuracy: 1.6680e-04 - val_loss: 0.3425 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 4.8626e-04 - val_loss: 0.3457 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 6.9937e-04 - val_loss: 0.3450 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3897 - accuracy: 7.7426e-04 - val_loss: 0.3449 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3937 - accuracy: 4.7985e-04 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3828 - accuracy: 0.0016 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3772 - accuracy: 0.0010 - val_loss: 0.3403 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.0020 - val_loss: 0.3411 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.0011 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 3.7551e-04 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/600\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3813 - accuracy: 9.0340e-04 - val_loss: 0.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.0019 - val_loss: 0.3393 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 7.9676e-04 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3808 - accuracy: 5.9763e-04 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3725 - accuracy: 5.2786e-04 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3874 - accuracy: 9.0410e-04 - val_loss: 0.3394 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 6.5152e-04 - val_loss: 0.3407 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 6.9792e-04 - val_loss: 0.3393 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 6.0619e-04 - val_loss: 0.3416 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.0012 - val_loss: 0.3369 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.0014 - val_loss: 0.3408 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.0011 - val_loss: 0.3407 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 9.2337e-04 - val_loss: 0.3380 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 6.5677e-04 - val_loss: 0.3387 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 1.2853e-04 - val_loss: 0.3393 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 5.1006e-04 - val_loss: 0.3362 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.0011 - val_loss: 0.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4013 - accuracy: 0.0012 - val_loss: 0.3362 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3789 - accuracy: 9.7209e-04 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 3.5884e-04 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 4.9009e-04 - val_loss: 0.3369 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.0019 - val_loss: 0.3351 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 5.2547e-04 - val_loss: 0.3448 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 7.8255e-04 - val_loss: 0.3400 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.0012 - val_loss: 0.3360 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 7.9688e-04 - val_loss: 0.3413 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 4.7896e-04 - val_loss: 0.3391 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.0010 - val_loss: 0.3381 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.0013 - val_loss: 0.3424 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 6.3165e-04 - val_loss: 0.3361 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.0011 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 5.8848e-04 - val_loss: 0.3400 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.0013 - val_loss: 0.3372 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 7.8077e-04 - val_loss: 0.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 6.9676e-04 - val_loss: 0.3370 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 4.9779e-04 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/600\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3854 - accuracy: 5.6993e-04 - val_loss: 0.3374 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 8.1998e-04 - val_loss: 0.3369 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.0015 - val_loss: 0.3375 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.0012 - val_loss: 0.3381 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 6.2141e-04 - val_loss: 0.3374 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 8.4638e-04 - val_loss: 0.3354 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 7.1164e-04 - val_loss: 0.3351 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.0011 - val_loss: 0.3361 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.0018 - val_loss: 0.3360 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 8.7043e-04 - val_loss: 0.3350 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 5.1662e-04 - val_loss: 0.3367 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.0020 - val_loss: 0.3356 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.0011 - val_loss: 0.3376 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 7.9574e-04 - val_loss: 0.3378 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.0012 - val_loss: 0.3330 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 7.4112e-04 - val_loss: 0.3351 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 2.1506e-04 - val_loss: 0.3399 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.0015 - val_loss: 0.3374 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/600\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3901 - accuracy: 0.0011 - val_loss: 0.3369 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.0022 - val_loss: 0.3372 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.0025 - val_loss: 0.3370 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3856 - accuracy: 9.1965e-04 - val_loss: 0.3366 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.0011 - val_loss: 0.3377 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.0017 - val_loss: 0.3371 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.0016 - val_loss: 0.3329 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.0012 - val_loss: 0.3373 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 9.1151e-04 - val_loss: 0.3392 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.0013 - val_loss: 0.3381 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 7.9799e-04 - val_loss: 0.3332 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3732 - accuracy: 0.0015 - val_loss: 0.3359 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.0017 - val_loss: 0.3354 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 7.6248e-04 - val_loss: 0.3376 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 8.3184e-04 - val_loss: 0.3383 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.0010 - val_loss: 0.3362 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.0010 - val_loss: 0.3358 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.0013 - val_loss: 0.3366 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3807 - accuracy: 0.0020 - val_loss: 0.3331 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 9.0230e-04 - val_loss: 0.3349 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3872 - accuracy: 0.0014 - val_loss: 0.3318 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.0013 - val_loss: 0.3343 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.0016 - val_loss: 0.3314 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3872 - accuracy: 0.0013 - val_loss: 0.3310 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.0017 - val_loss: 0.3323 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.0011 - val_loss: 0.3303 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 7.8501e-04 - val_loss: 0.3351 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 8.8047e-04 - val_loss: 0.3296 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 8.8041e-04 - val_loss: 0.3338 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.0041 - val_loss: 0.3309 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.0012 - val_loss: 0.3379 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.0014 - val_loss: 0.3354 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 8.5492e-04 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 7.9595e-04 - val_loss: 0.3361 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3860 - accuracy: 2.8109e-04 - val_loss: 0.3341 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.0036 - val_loss: 0.3341 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/600\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3781 - accuracy: 0.0013 - val_loss: 0.3360 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.0040 - val_loss: 0.3321 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.0018 - val_loss: 0.3366 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.0017 - val_loss: 0.3328 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3816 - accuracy: 0.0015 - val_loss: 0.3330 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.0019 - val_loss: 0.3395 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.0028 - val_loss: 0.3347 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.0011 - val_loss: 0.3334 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.0013 - val_loss: 0.3352 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.0023 - val_loss: 0.3354 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/600\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3821 - accuracy: 9.3934e-04 - val_loss: 0.3361 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.0030 - val_loss: 0.3346 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.0016 - val_loss: 0.3341 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.0030 - val_loss: 0.3330 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.0021 - val_loss: 0.3326 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 8.2893e-04 - val_loss: 0.3364 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/600\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.0012 - val_loss: 0.3342 - val_accuracy: 0.0000e+00\n",
            "Epoch 00187: early stopping\n",
            "CPU times: user 1min 38s, sys: 8.16 s, total: 1min 47s\n",
            "Wall time: 1min 30s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbae6673518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "v82q5MoUmrrb",
        "outputId": "cf5d69a1-6eae-471f-a175-599b87adf1b7"
      },
      "source": [
        "model_loss = pd.DataFrame(model.history.history)\r\n",
        "model_loss.plot()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbaea04d9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUO456vpp2cd",
        "outputId": "2812019c-c4a2-4855-ec96-c53aad4f69a5"
      },
      "source": [
        "\r\n",
        "y_predicted = model.predict(X_test)\r\n",
        "\r\n",
        "y_predicted = (y_predicted > 0.5)\r\n",
        "print(np.concatenate((y_predicted.reshape(len(y_predicted),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnbf4gNcnvcr",
        "outputId": "48df8308-fdab-4e93-eede-62fbc88a4278"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\r\n",
        "print(classification_report(y_test,y_predicted))\r\n",
        "print(confusion_matrix(y_test,y_predicted))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.92      1577\n",
            "           1       0.83      0.43      0.56       423\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.85      0.70      0.74      2000\n",
            "weighted avg       0.86      0.86      0.84      2000\n",
            "\n",
            "[[1539   38]\n",
            " [ 242  181]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBxAJwU5qNy4",
        "outputId": "152f5008-f441-4fba-a69e-012e73a87315"
      },
      "source": [
        "accuracy_score(y_test, y_predicted)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbScvjCmqErR"
      },
      "source": [
        "**The Accuracy obtained in method 3 = 0.86**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTJXI_Tvn0xm"
      },
      "source": [
        "Hence, highest accuracy is received when epochs are 600. Also, when we are using dropout with early stopping for model training. hence both method 1 and 3 can be used for prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rthMwOo6sxaD"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "bA2_3zXTrB4l",
        "outputId": "8f84bef8-6f5d-4992-c72b-97d75d7ffee0"
      },
      "source": [
        "'''Geography: France\r\n",
        "Credit Score: 499\r\n",
        "Gender: Male\r\n",
        "Age: 39 years old\r\n",
        "Tenure: 3 years\r\n",
        "Balance: $50000\r\n",
        "Number of Products: 2\r\n",
        "Does this customer have a credit card ? Yes\r\n",
        "Is this customer an Active Member: Yes\r\n",
        "Estimated Salary: $60000'''\r\n",
        "\r\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Geography: France\\nCredit Score: 499\\nGender: Male\\nAge: 39 years old\\nTenure: 3 years\\nBalance: $50000\\nNumber of Products: 2\\nDoes this customer have a credit card ? Yes\\nIs this customer an Active Member: Yes\\nEstimated Salary: $60000'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQMRzw8Xs5hJ",
        "outputId": "a5b5acfc-9367-40e6-af2a-217bb6ed7663"
      },
      "source": [
        "ann_prediction = model.predict(scaler.transform(np.array([[499, 39, 3, 50000, 2, 1, 1, 60000, 1, 0, 0, 0, 1]])))\r\n",
        "\r\n",
        "ann_prediction = (ann_prediction > 0.5 )\r\n",
        "print(ann_prediction)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrLHqULetUNF"
      },
      "source": [
        "# THANK YOU"
      ],
      "execution_count": 106,
      "outputs": []
    }
  ]
}